Scrapy Crawler за MkWordNet
===========================
Овој проект е наменет за собирање на македонски текстови во дигитална форма.
Главната цел е да се соберат текстови на македонски јазик и да се направи
нешто слично на [Princeton Wordnet][PWN], или уште поблиску [MultiWordnet][MWN]

[PWN]: http://wordnetweb.princeton.edu/perl/webwn
[MWN]: http://multiwordnet.fbk.eu/english/home.php

Покажувачи :)
-------------

За да го симнете проектов:

    $ git clone git://github.com/mkwordnet/crawler.git

Кој сака веднаш да се уклучи може да [форка][fork-a-repo]

[fork-a-repo]: http://help.github.com/fork-a-repo/

Идејата е во oвоа репо да се чуваат сите работи поврзани
со crawler-от, а во друго работите поврзани со NLP.

Кога ќе бидете сигурни дека сѐ работи како што треба пуштете [pull request][pr]

[pr]: http://help.github.com/send-pull-requests/



SPIDERS
-------

1) crawler/spiders/a1.py 
    - содржи 2 начини на собирање на содржините
    - првиот е класично собирање на содржините од странат на страна
    - вториот начин почнува од страна која што содржи листа статии групирани 
      по новинари (од 2001 па наваму)

2) crawler/spiders/dnevnik.py - не е целосно доправен и истестиран.

Додавање на нов spider
______________________

1. во фолдерот crawler/spiders/ додадете датотека со екстензија .py и крстете
ја според називот на сајтот (како што е направено за останатите)
2. креирајте класа која се вика како сајтот и додадете Spider
3. **name** е променлива во која што се чува името кое се повикува со scrapy crawl.
пр. $ scrapy crawl a1-novinari ќе го пушти кролерот според конфигурацијата внесена во променливите во класата
4. **rules** содржи конфигурација и филтри за сите URL-а кои може да ги посети spider-от
(внимавајте на регуларните изрази (), ?, +, * ... се специјални знаци во изразите
и пред секој стринг треба да ставите r за да се третира како regex)
5. **parse_item** е главна метода за вадење на содржините од земениот HTML.
За вадење на содржините од HTML-от и внесување во Item променливата се користи [XPath][xpath]

[xpath]: http://www.w3schools.com/xpath/xpath_syntax.asp


**P.S.
Знам дека crawler е многу generic име, ама немаше опции. Не го користете името во други проекти :)
